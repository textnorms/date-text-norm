{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5: V11 Pt-incomplete-dates.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/textnorms/date_text_norm/blob/master/T5_V11_Pt_incomplete_dates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcMfqlK-0HLY",
        "colab_type": "code",
        "outputId": "9f7c0352-36ea-41e6-b3da-bfaf3a71abe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun  3 13:42:55 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    76W / 149W |   2052MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-1Lmkfv6g2j",
        "colab_type": "code",
        "outputId": "940e3f2f-9efa-40ff-f375-422c0f5668a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "! rm -rf date*\n",
        "! git clone https://github.com/textnorms/date_text_norm.git\n",
        "! cp -r date_text_norm/syntetic_data_En/ .\n",
        "! cp -r date_text_norm/syntetic_data_Pt/ .\n",
        "\n",
        "! pip install -q num2words transformers\n",
        "! pip install -q transformers"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'date_text_norm'...\n",
            "remote: Enumerating objects: 204, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/204)\u001b[K\rremote: Counting objects:   1% (3/204)\u001b[K\rremote: Counting objects:   2% (5/204)\u001b[K\rremote: Counting objects:   3% (7/204)\u001b[K\rremote: Counting objects:   4% (9/204)\u001b[K\rremote: Counting objects:   5% (11/204)\u001b[K\rremote: Counting objects:   6% (13/204)\u001b[K\rremote: Counting objects:   7% (15/204)\u001b[K\rremote: Counting objects:   8% (17/204)\u001b[K\rremote: Counting objects:   9% (19/204)\u001b[K\rremote: Counting objects:  10% (21/204)\u001b[K\rremote: Counting objects:  11% (23/204)\u001b[K\rremote: Counting objects:  12% (25/204)\u001b[K\rremote: Counting objects:  13% (27/204)\u001b[K\rremote: Counting objects:  14% (29/204)\u001b[K\rremote: Counting objects:  15% (31/204)\u001b[K\rremote: Counting objects:  16% (33/204)\u001b[K\rremote: Counting objects:  17% (35/204)\u001b[K\rremote: Counting objects:  18% (37/204)\u001b[K\rremote: Counting objects:  19% (39/204)\u001b[K\rremote: Counting objects:  20% (41/204)\u001b[K\rremote: Counting objects:  21% (43/204)\u001b[K\rremote: Counting objects:  22% (45/204)\u001b[K\rremote: Counting objects:  23% (47/204)\u001b[K\rremote: Counting objects:  24% (49/204)\u001b[K\rremote: Counting objects:  25% (51/204)\u001b[K\rremote: Counting objects:  26% (54/204)\u001b[K\rremote: Counting objects:  27% (56/204)\u001b[K\rremote: Counting objects:  28% (58/204)\u001b[K\rremote: Counting objects:  29% (60/204)\u001b[K\rremote: Counting objects:  30% (62/204)\u001b[K\rremote: Counting objects:  31% (64/204)\u001b[K\rremote: Counting objects:  32% (66/204)\u001b[K\rremote: Counting objects:  33% (68/204)\u001b[K\rremote: Counting objects:  34% (70/204)\u001b[K\rremote: Counting objects:  35% (72/204)\u001b[K\rremote: Counting objects:  36% (74/204)\u001b[K\rremote: Counting objects:  37% (76/204)\u001b[K\rremote: Counting objects:  38% (78/204)\u001b[K\rremote: Counting objects:  39% (80/204)\u001b[K\rremote: Counting objects:  40% (82/204)\u001b[K\rremote: Counting objects:  41% (84/204)\u001b[K\rremote: Counting objects:  42% (86/204)\u001b[K\rremote: Counting objects:  43% (88/204)\u001b[K\rremote: Counting objects:  44% (90/204)\u001b[K\rremote: Counting objects:  45% (92/204)\u001b[K\rremote: Counting objects:  46% (94/204)\u001b[K\rremote: Counting objects:  47% (96/204)\u001b[K\rremote: Counting objects:  48% (98/204)\u001b[K\rremote: Counting objects:  49% (100/204)\u001b[K\rremote: Counting objects:  50% (102/204)\u001b[K\rremote: Counting objects:  51% (105/204)\u001b[K\rremote: Counting objects:  52% (107/204)\u001b[K\rremote: Counting objects:  53% (109/204)\u001b[K\rremote: Counting objects:  54% (111/204)\u001b[K\rremote: Counting objects:  55% (113/204)\u001b[K\rremote: Counting objects:  56% (115/204)\u001b[K\rremote: Counting objects:  57% (117/204)\u001b[K\rremote: Counting objects:  58% (119/204)\u001b[K\rremote: Counting objects:  59% (121/204)\u001b[K\rremote: Counting objects:  60% (123/204)\u001b[K\rremote: Counting objects:  61% (125/204)\u001b[K\rremote: Counting objects:  62% (127/204)\u001b[K\rremote: Counting objects:  63% (129/204)\u001b[K\rremote: Counting objects:  64% (131/204)\u001b[K\rremote: Counting objects:  65% (133/204)\u001b[K\rremote: Counting objects:  66% (135/204)\u001b[K\rremote: Counting objects:  67% (137/204)\u001b[K\rremote: Counting objects:  68% (139/204)\u001b[K\rremote: Counting objects:  69% (141/204)\u001b[K\rremote: Counting objects:  70% (143/204)\u001b[K\rremote: Counting objects:  71% (145/204)\u001b[K\rremote: Counting objects:  72% (147/204)\u001b[K\rremote: Counting objects:  73% (149/204)\u001b[K\rremote: Counting objects:  74% (151/204)\u001b[K\rremote: Counting objects:  75% (153/204)\u001b[K\rremote: Counting objects:  76% (156/204)\u001b[K\rremote: Counting objects:  77% (158/204)\u001b[K\rremote: Counting objects:  78% (160/204)\u001b[K\rremote: Counting objects:  79% (162/204)\u001b[K\rremote: Counting objects:  80% (164/204)\u001b[K\rremote: Counting objects:  81% (166/204)\u001b[K\rremote: Counting objects:  82% (168/204)\u001b[K\rremote: Counting objects:  83% (170/204)\u001b[K\rremote: Counting objects:  84% (172/204)\u001b[K\rremote: Counting objects:  85% (174/204)\u001b[K\rremote: Counting objects:  86% (176/204)\u001b[K\rremote: Counting objects:  87% (178/204)\u001b[K\rremote: Counting objects:  88% (180/204)\u001b[K\rremote: Counting objects:  89% (182/204)\u001b[K\rremote: Counting objects:  90% (184/204)\u001b[K\rremote: Counting objects:  91% (186/204)\u001b[K\rremote: Counting objects:  92% (188/204)\u001b[K\rremote: Counting objects:  93% (190/204)\u001b[K\rremote: Counting objects:  94% (192/204)\u001b[K\rremote: Counting objects:  95% (194/204)\u001b[K\rremote: Counting objects:  96% (196/204)\u001b[K\rremote: Counting objects:  97% (198/204)\u001b[K\rremote: Counting objects:  98% (200/204)\u001b[K\rremote: Counting objects:  99% (202/204)\u001b[K\rremote: Counting objects: 100% (204/204)\u001b[K\rremote: Counting objects: 100% (204/204), done.\u001b[K\n",
            "remote: Compressing objects: 100% (166/166), done.\u001b[K\n",
            "remote: Total 204 (delta 111), reused 78 (delta 33), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (204/204), 1.41 MiB | 3.47 MiB/s, done.\n",
            "Resolving deltas: 100% (111/111), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAYiZO6Teo-y",
        "colab_type": "text"
      },
      "source": [
        "# Libs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmrMJ5fSgr3P",
        "colab_type": "text"
      },
      "source": [
        "### Choose Language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbOvMx-Igq7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LANGUAGE = 'Pt'\n",
        "# LANGUAGE = 'En'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nok2mtt_1021",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Synthetic data generator\n",
        "\n",
        "if LANGUAGE == 'En':\n",
        "    from syntetic_data_En import DateTextGenerator \n",
        "\n",
        "if LANGUAGE == 'Pt':\n",
        "    from syntetic_data_Pt import DateTextGenerator \n",
        "\n",
        "# PyTorch\n",
        "import torch \n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
        "\n",
        "# Matplot lib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhdTvVgiYBw0",
        "colab_type": "text"
      },
      "source": [
        "### Deterministic experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm7tAsiUYMOU",
        "colab_type": "code",
        "outputId": "a780b381-8d77-4672-f893-b5c26bc03860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "manual_seed = 2357 # only primes, cuz I like\n",
        "def deterministic(rep=True):\n",
        "    if rep:\n",
        "        np.random.seed(manual_seed)\n",
        "        torch.manual_seed(manual_seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(manual_seed)\n",
        "            torch.cuda.manual_seed_all(manual_seed)\n",
        "        torch.backends.cudnn.enabled = False \n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        print(f'Deterministic experiment, seed: {manual_seed}')\n",
        "    else:\n",
        "        print('Random experiment')\n",
        "\n",
        "deterministic()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deterministic experiment, seed: 2357\n",
            "Using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFHYoyzwOHDO",
        "colab_type": "text"
      },
      "source": [
        "# Config constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r8O913HOK9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model params\n",
        "MODEL_SZ = 't5-small' # 't5-base'\n",
        "TOK = T5Tokenizer.from_pretrained(MODEL_SZ)\n",
        "MAX_LEN_SRC  = 48\n",
        "MAX_LEN_TRGT = 12\n",
        "\n",
        "# Train params\n",
        "BATCH_SZ = 16\n",
        "N_EPOCHS = 50\n",
        "WINDOW   = 7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yeoFiMYXe8Z",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ52EJP6Fy5v",
        "colab_type": "code",
        "outputId": "f6a31838-c1f1-4b9e-9cc0-41af78214073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pd.set_option('display.max_rows',70)\n",
        "\n",
        "datas = DateTextGenerator(start_date='01/01/1921',\n",
        "                          end_date='31/12/2120',\n",
        "                          text_noise_rate=0.3)\n",
        "\n",
        "examples = datas.generate_demo(date='4/11/1983'); examples"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Pattern</th>\n",
              "      <th>Generated Text</th>\n",
              "      <th>Origin Sample</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>quatro de novembro de 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>quatro de nov de mil, novecentos e oitenta e três</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>quatro de novembro de mil, novecentos e oitent...</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>quarto dia do mês onze de mil, novecentos e oi...</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4 de Novembro de 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>4 de novembro de mil, novecentos e oitenta e três</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>4-11 de mil, novecentos e oitenta e três</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>quatro - 11 - 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>quatro de novembro - 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>4º de novembro de 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>4º - 11 - 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>4º / 11 / 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>4º / Novembro / 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>4 / novembro / 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>quatro novembro mil, novecentos e oitenta e três</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>4 novembro mil, novecentos e oitenta e três</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>4/11 mil, novecentos e oitenta e três</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>4.11 mil, novecentos e oitenta e três</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>4-11 mil, novecentos e oitenta e três</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>quatro/novembro/mil, novecentos e oitenta e três</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>4 do mês onze de 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>4-11-1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>4 - 11 - 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>4-11-1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>4 - 11 - 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>4-novembro-1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>4 - novembro - 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>4-nov-1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>4 - nov - 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>4.11.1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>31</td>\n",
              "      <td>4 . 11 . 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>32</td>\n",
              "      <td>4.11.1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>33</td>\n",
              "      <td>4 . 11 . 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>34</td>\n",
              "      <td>4.novembro.1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>35</td>\n",
              "      <td>4 . novembro . 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>36</td>\n",
              "      <td>4.nov.1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>37</td>\n",
              "      <td>4 . nov . 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>38</td>\n",
              "      <td>4/11/1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>39</td>\n",
              "      <td>4 / 11 / 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>40</td>\n",
              "      <td>4/novembro/1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>41</td>\n",
              "      <td>4 / novembro / 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>42</td>\n",
              "      <td>4/nov/1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>43</td>\n",
              "      <td>4 / nov / 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>44</td>\n",
              "      <td>4/11/1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>45</td>\n",
              "      <td>4 / 11 / 1983</td>\n",
              "      <td>4/11/1983</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Input Pattern  ... Origin Sample\n",
              "0              1  ...     4/11/1983\n",
              "1              2  ...     4/11/1983\n",
              "2              3  ...     4/11/1983\n",
              "3              4  ...     4/11/1983\n",
              "4              5  ...     4/11/1983\n",
              "5              6  ...     4/11/1983\n",
              "6              7  ...     4/11/1983\n",
              "7              8  ...     4/11/1983\n",
              "8              9  ...     4/11/1983\n",
              "9             10  ...     4/11/1983\n",
              "10            11  ...     4/11/1983\n",
              "11            12  ...     4/11/1983\n",
              "12            13  ...     4/11/1983\n",
              "13            14  ...     4/11/1983\n",
              "14            15  ...     4/11/1983\n",
              "15            16  ...     4/11/1983\n",
              "16            17  ...     4/11/1983\n",
              "17            18  ...     4/11/1983\n",
              "18            19  ...     4/11/1983\n",
              "19            20  ...     4/11/1983\n",
              "20            21  ...     4/11/1983\n",
              "21            22  ...     4/11/1983\n",
              "22            23  ...     4/11/1983\n",
              "23            24  ...     4/11/1983\n",
              "24            25  ...     4/11/1983\n",
              "25            26  ...     4/11/1983\n",
              "26            27  ...     4/11/1983\n",
              "27            28  ...     4/11/1983\n",
              "28            29  ...     4/11/1983\n",
              "29            30  ...     4/11/1983\n",
              "30            31  ...     4/11/1983\n",
              "31            32  ...     4/11/1983\n",
              "32            33  ...     4/11/1983\n",
              "33            34  ...     4/11/1983\n",
              "34            35  ...     4/11/1983\n",
              "35            36  ...     4/11/1983\n",
              "36            37  ...     4/11/1983\n",
              "37            38  ...     4/11/1983\n",
              "38            39  ...     4/11/1983\n",
              "39            40  ...     4/11/1983\n",
              "40            41  ...     4/11/1983\n",
              "41            42  ...     4/11/1983\n",
              "42            43  ...     4/11/1983\n",
              "43            44  ...     4/11/1983\n",
              "44            45  ...     4/11/1983\n",
              "\n",
              "[45 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpMWc1TrNvKS",
        "colab_type": "code",
        "outputId": "0cf73cf3-bdbc-49f6-ae0e-d8f6a19de532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = datas.generate_date_dataset() \n",
        "f'df: {df.shape}'"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'df: (75815, 5)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdMrRLTELs-L",
        "colab_type": "code",
        "outputId": "a026445c-d874-4edf-b01b-03d5f4494935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Pattern</th>\n",
              "      <th>Noise Type</th>\n",
              "      <th>Input</th>\n",
              "      <th>Target</th>\n",
              "      <th>Target Format</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15</td>\n",
              "      <td>N/A</td>\n",
              "      <td>um janeiro mil, novecentos e vinte e um</td>\n",
              "      <td>01/01/1921</td>\n",
              "      <td>DD/MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24</td>\n",
              "      <td>N/A</td>\n",
              "      <td>02-01-1921</td>\n",
              "      <td>02/01/1921</td>\n",
              "      <td>DD/MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>43</td>\n",
              "      <td>[unexpected_space_noise]</td>\n",
              "      <td>3  / jan / 1921</td>\n",
              "      <td>03/01/1921</td>\n",
              "      <td>DD/MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[remove_char_noise]</td>\n",
              "      <td>uatro dejaneiro de 1921</td>\n",
              "      <td>04/01/1921</td>\n",
              "      <td>DD/MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31</td>\n",
              "      <td>[unexpected_space_noise, lookalike_replace_noi...</td>\n",
              "      <td>o5 . 1  .  921</td>\n",
              "      <td>05/01/1921</td>\n",
              "      <td>DD/MM/YYYY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Input Pattern  ... Target Format\n",
              "0             15  ...    DD/MM/YYYY\n",
              "1             24  ...    DD/MM/YYYY\n",
              "2             43  ...    DD/MM/YYYY\n",
              "3              1  ...    DD/MM/YYYY\n",
              "4             31  ...    DD/MM/YYYY\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wojl91rJNEmC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "51b6ac34-f41a-46e3-d1bb-77bc40545bc4"
      },
      "source": [
        "df.loc[df['Target Format'] == 'DD/MM']"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Pattern</th>\n",
              "      <th>Noise Type</th>\n",
              "      <th>Input</th>\n",
              "      <th>Target</th>\n",
              "      <th>Target Format</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75449</th>\n",
              "      <td>21</td>\n",
              "      <td>[remove_char_noise, unexpected_space_noise, lo...</td>\n",
              "      <td>0 1do ê s un</td>\n",
              "      <td>01/01</td>\n",
              "      <td>DD/MM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75450</th>\n",
              "      <td>43</td>\n",
              "      <td>[remove_char_noise, lookalike_replace_noise, u...</td>\n",
              "      <td>2  j am</td>\n",
              "      <td>02/01</td>\n",
              "      <td>DD/MM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75451</th>\n",
              "      <td>36</td>\n",
              "      <td>[unexpected_space_noise, remove_char_noise]</td>\n",
              "      <td>03.ja n</td>\n",
              "      <td>03/01</td>\n",
              "      <td>DD/MM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75452</th>\n",
              "      <td>28</td>\n",
              "      <td>N/A</td>\n",
              "      <td>04-jan</td>\n",
              "      <td>04/01</td>\n",
              "      <td>DD/MM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75453</th>\n",
              "      <td>13</td>\n",
              "      <td>N/A</td>\n",
              "      <td>05º / Janeiro</td>\n",
              "      <td>05/01</td>\n",
              "      <td>DD/MM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75810</th>\n",
              "      <td>38</td>\n",
              "      <td>[unexpected_space_noise]</td>\n",
              "      <td>2 8/12</td>\n",
              "      <td>28/12</td>\n",
              "      <td>DD/MM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75811</th>\n",
              "      <td>4</td>\n",
              "      <td>[unexpected_space_noise, remove_char_noise, lo...</td>\n",
              "      <td>u igésimo nono dia do mês d0e</td>\n",
              "      <td>29/12</td>\n",
              "      <td>DD/MM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75812</th>\n",
              "      <td>13</td>\n",
              "      <td>N/A</td>\n",
              "      <td>30º / Dezembro</td>\n",
              "      <td>30/12</td>\n",
              "      <td>DD/MM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75813</th>\n",
              "      <td>44</td>\n",
              "      <td>[remove_char_noise]</td>\n",
              "      <td>31/2</td>\n",
              "      <td>31/12</td>\n",
              "      <td>DD/MM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75814</th>\n",
              "      <td>40</td>\n",
              "      <td>N/A</td>\n",
              "      <td>1/janeiro</td>\n",
              "      <td>01/01</td>\n",
              "      <td>DD/MM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>366 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Input Pattern  ... Target Format\n",
              "75449             21  ...         DD/MM\n",
              "75450             43  ...         DD/MM\n",
              "75451             36  ...         DD/MM\n",
              "75452             28  ...         DD/MM\n",
              "75453             13  ...         DD/MM\n",
              "...              ...  ...           ...\n",
              "75810             38  ...         DD/MM\n",
              "75811              4  ...         DD/MM\n",
              "75812             13  ...         DD/MM\n",
              "75813             44  ...         DD/MM\n",
              "75814             40  ...         DD/MM\n",
              "\n",
              "[366 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UquMxgpcNO3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "b7e4245b-1a74-4230-9331-bcf8ca96683a"
      },
      "source": [
        "df.loc[df['Target Format'] == 'MM/YYYY']"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Pattern</th>\n",
              "      <th>Noise Type</th>\n",
              "      <th>Input</th>\n",
              "      <th>Target</th>\n",
              "      <th>Target Format</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>73049</th>\n",
              "      <td>13</td>\n",
              "      <td>N/A</td>\n",
              "      <td>Janeiro / 1921</td>\n",
              "      <td>01/1921</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73050</th>\n",
              "      <td>29</td>\n",
              "      <td>N/A</td>\n",
              "      <td>fev - 1921</td>\n",
              "      <td>02/1921</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73051</th>\n",
              "      <td>16</td>\n",
              "      <td>N/A</td>\n",
              "      <td>março mil, novecentos e vinte e um</td>\n",
              "      <td>03/1921</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73052</th>\n",
              "      <td>19</td>\n",
              "      <td>N/A</td>\n",
              "      <td>04 mil, novecentos e vinte e um</td>\n",
              "      <td>04/1921</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73053</th>\n",
              "      <td>34</td>\n",
              "      <td>N/A</td>\n",
              "      <td>maio.1921</td>\n",
              "      <td>05/1921</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75444</th>\n",
              "      <td>6</td>\n",
              "      <td>[lookalike_replace_noise, remove_char_noise]</td>\n",
              "      <td>agosto de dolsnil, cento e vinte</td>\n",
              "      <td>08/2120</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75445</th>\n",
              "      <td>21</td>\n",
              "      <td>N/A</td>\n",
              "      <td>nove de 2120</td>\n",
              "      <td>09/2120</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75446</th>\n",
              "      <td>4</td>\n",
              "      <td>N/A</td>\n",
              "      <td>mês dez de dois mil, cento e vinte</td>\n",
              "      <td>10/2120</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75447</th>\n",
              "      <td>22</td>\n",
              "      <td>N/A</td>\n",
              "      <td>11-2120</td>\n",
              "      <td>11/2120</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75448</th>\n",
              "      <td>29</td>\n",
              "      <td>N/A</td>\n",
              "      <td>dez - 2120</td>\n",
              "      <td>12/2120</td>\n",
              "      <td>MM/YYYY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2400 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Input Pattern  ... Target Format\n",
              "73049             13  ...       MM/YYYY\n",
              "73050             29  ...       MM/YYYY\n",
              "73051             16  ...       MM/YYYY\n",
              "73052             19  ...       MM/YYYY\n",
              "73053             34  ...       MM/YYYY\n",
              "...              ...  ...           ...\n",
              "75444              6  ...       MM/YYYY\n",
              "75445             21  ...       MM/YYYY\n",
              "75446              4  ...       MM/YYYY\n",
              "75447             22  ...       MM/YYYY\n",
              "75448             29  ...       MM/YYYY\n",
              "\n",
              "[2400 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5sp50kPNZhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing dates in the defined Target Format\n",
        "df = df.loc[df['Target Format'] != 'DD/MM/YYYY']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uif9PsFKRrxI",
        "colab_type": "text"
      },
      "source": [
        "## Function to split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfBx9nMkQ7Q8",
        "colab_type": "code",
        "outputId": "a1318d95-b802-4ba0-a67d-682332d36717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def split_data(df, test_size=0.2, verbose=True):\n",
        "    l = list(set(df['Input Pattern'].values))\n",
        "    num_test = int(len(l)*test_size)\n",
        "    test_methods = [random.randint(1, len(l)) for _ in range(num_test)]\n",
        "    print(test_methods)\n",
        "    df_test = df[df['Input Pattern'].isin(test_methods)]\n",
        "    print(df_test.shape)\n",
        "    x_test = df_test.Input.values\n",
        "    y_test = df_test.Target.values\n",
        "\n",
        "    df_train = df[~df['Input Pattern'].isin(test_methods)]\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        df_train.Input.values,\n",
        "        df_train.Target.values,\n",
        "        shuffle=True, \n",
        "        test_size=test_size,\n",
        "        random_state=manual_seed\n",
        "        )\n",
        "    if verbose:\n",
        "        print(f'Date types of test set: {test_methods} with len: {len(test_methods)}')\n",
        "        print(f'x_train: {len(x_train)}  --  y_train: {len(y_train)}\\n\\\n",
        "x_val:   {len(x_val)}  --  y_val:   {len(y_val)}\\n\\\n",
        "x_test:  {len(x_test)}  --  y_test:  {len(y_test)}')\n",
        "\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
        "\n",
        "# creating sets\n",
        "x_train, y_train, x_val, y_val, x_test, y_test = split_data(df, \n",
        "                                                            test_size=0.25, \n",
        "                                                            verbose=True)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 12, 4, 6, 45, 18, 28, 13, 6, 26, 5]\n",
            "(565, 5)\n",
            "Date types of test set: [4, 12, 4, 6, 45, 18, 28, 13, 6, 26, 5] with len: 11\n",
            "x_train: 1650  --  y_train: 1650\n",
            "x_val:   551  --  y_val:   551\n",
            "x_test:  565  --  y_test:  565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygsMXnkCyrVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DateDataset(Dataset):\n",
        "    def __init__(self, data, label, tokenizer, source_max_length, target_max_length):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "        self.source_max_length = source_max_length\n",
        "        self.target_max_length = target_max_length\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        source = self.data[idx]\n",
        "        target = self.label[idx]\n",
        "\n",
        "        source_tokenized = self.tokenizer.encode_plus(\n",
        "            f'{source} {self.tokenizer.eos_token}',\n",
        "            max_length=self.source_max_length,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors='pt')\n",
        "\n",
        "        target_tokenized = self.tokenizer.encode_plus(\n",
        "            f'{target} {self.tokenizer.eos_token}',\n",
        "            max_length=self.target_max_length,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors='pt')\n",
        "\n",
        "        source_token_ids = source_tokenized['input_ids'].squeeze()\n",
        "        source_mask = source_tokenized['attention_mask'].squeeze()\n",
        "        target_token_ids = target_tokenized['input_ids'].squeeze()\n",
        "        \n",
        "        return source_token_ids, source_mask, target_token_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cloyt0tIwIiD",
        "colab_type": "text"
      },
      "source": [
        "## Checking the DateDataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoKiQXCvwGrP",
        "colab_type": "code",
        "outputId": "8b228c37-5f60-480a-a671-0962abacb392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "dataset_debug = DateDataset(\n",
        "    x_train, \n",
        "    y_train,\n",
        "    TOK,\n",
        "    MAX_LEN_SRC,\n",
        "    MAX_LEN_TRGT,\n",
        "    )\n",
        "\n",
        "dataloader_checking = DataLoader(\n",
        "    dataset_debug, \n",
        "    batch_size=1, \n",
        "    shuffle=True, \n",
        "    num_workers=0\n",
        "    )\n",
        "\n",
        "source_token_ids, source_mask, target_token_ids = next(iter(dataloader_checking))\n",
        "print(f'source_token_ids:\\n {source_token_ids} --- shape:{source_token_ids.shape}')\n",
        "print(f'source_mask:\\n {source_mask} --- shape:{source_mask.shape}')\n",
        "print(f'target_token_ids:\\n {target_token_ids} --- shape:{target_token_ids.shape}')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source_token_ids:\n",
            " tensor([[10668,     3,    18, 14834,     1,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0]]) --- shape:torch.Size([1, 48])\n",
            "source_mask:\n",
            " tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]) --- shape:torch.Size([1, 48])\n",
            "target_token_ids:\n",
            " tensor([[10668, 13523,  3940,     1,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0]]) --- shape:torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG1O12UoWYaM",
        "colab_type": "text"
      },
      "source": [
        "## Datasets e Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7AlRyeOW8GN",
        "colab_type": "code",
        "outputId": "203f93a9-dbc2-4fa0-d310-8928d1dc2533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# datasets\n",
        "ds_debug = DateDataset(x_train[:BATCH_SZ], y_train[:BATCH_SZ], TOK, MAX_LEN_SRC, MAX_LEN_TRGT)\n",
        "ds_train = DateDataset(x_train, y_train, TOK, MAX_LEN_SRC, MAX_LEN_TRGT)\n",
        "ds_valid = DateDataset(x_val, y_val, TOK, MAX_LEN_SRC, MAX_LEN_TRGT)\n",
        "ds_test  = DateDataset(x_test, y_test, TOK, MAX_LEN_SRC, MAX_LEN_TRGT)\n",
        "\n",
        "print('Datasets len:')\n",
        "print(f'len ds_debug: {len(ds_debug)}')\n",
        "print(f'len ds_train: {len(ds_train)}')\n",
        "print(f'len ds_valid: {len(ds_valid)}')\n",
        "print(f'len ds_test:  {len(ds_test)}')\n",
        "\n",
        "# dataloaders\n",
        "dataloaders = {\n",
        "    'debug': DataLoader(\n",
        "         ds_debug,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=True,\n",
        "         num_workers=2,\n",
        "         pin_memory=True),\n",
        "    'train': DataLoader(\n",
        "         ds_train,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=True,\n",
        "         num_workers=2,\n",
        "         pin_memory=True),\n",
        "    'valid': DataLoader(\n",
        "         ds_valid,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=False,\n",
        "         num_workers=2,\n",
        "         pin_memory=True),\n",
        "    'test': DataLoader(\n",
        "         ds_test,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=False,\n",
        "         num_workers=2,\n",
        "         pin_memory=True),\n",
        "               }\n",
        "# sanity check\n",
        "print('\\nDataloaders len (in batch):')\n",
        "dl_sizes = {x: len(dataloaders[x]) for x in dataloaders.keys()}; dl_sizes"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datasets len:\n",
            "len ds_debug: 16\n",
            "len ds_train: 1650\n",
            "len ds_valid: 551\n",
            "len ds_test:  565\n",
            "\n",
            "Dataloaders len (in batch):\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'debug': 1, 'test': 36, 'train': 104, 'valid': 35}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3rqg6r7am-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testando o dataloader \n",
        "source_token_ids, source_mask, target_token_ids = next(iter(dataloaders['debug']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb4AnOJzBXK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_SZ)\n",
        "    \n",
        "    def forward(self, token_ids, att_mask, labels):\n",
        "        outputs = self.model.forward(\n",
        "            input_ids=token_ids, \n",
        "            attention_mask=att_mask,\n",
        "            lm_labels=labels\n",
        "            )\n",
        "        return outputs[0] # loss\n",
        "    \n",
        "    @torch.no_grad()    \n",
        "    def generate(self, token_ids, att_mask, max_len_target):\n",
        "        predict = self.model.generate(\n",
        "            input_ids=token_ids, \n",
        "            attention_mask=att_mask,\n",
        "            max_length=max_len_target\n",
        "            )\n",
        "        return predict\n",
        "    \n",
        "    @torch.no_grad()  \n",
        "    def generate_example(self, text_input, tokenizer, max_len_source=MAX_LEN_SRC):\n",
        "\n",
        "        self.model.eval()\n",
        "        \n",
        "        example_tokenized = tokenizer.encode_plus(\n",
        "            f'{text_input} {tokenizer.eos_token}',\n",
        "            max_length=max_len_source,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors='pt')\n",
        "            \n",
        "        example_token_ids = example_tokenized['input_ids']\n",
        "        example_mask = example_tokenized['attention_mask']\n",
        "\n",
        "        predicted_example = self.model.generate(\n",
        "            input_ids=example_token_ids.to(device), \n",
        "            attention_mask=example_mask.to(device),\n",
        "            max_length=MAX_LEN_TRGT\n",
        "            )\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        out_text = [tokenizer.decode(text) for text in predicted_example]\n",
        "        \n",
        "        return out_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq9AMCaNuWMU",
        "colab_type": "text"
      },
      "source": [
        "## Train and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X6hklAUXxGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# acc metric for text inputs\n",
        "def acc_in_text(trues, preds): \n",
        "    acc = []\n",
        "    for d in zip(trues, preds):\n",
        "        if d[0] == d[1]:\n",
        "            acc.append(1)\n",
        "        else:\n",
        "            acc.append(0)\n",
        "    return acc # bool\n",
        "\n",
        "def train(model, device, train_loader, optimizer):\n",
        "    loss_train = []\n",
        "    model.train()\n",
        "    for source_token_ids, source_mask, target_token_ids in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(\n",
        "            source_token_ids.to(device), \n",
        "            source_mask.to(device), \n",
        "            target_token_ids.to(device)\n",
        "            )\n",
        "        \n",
        "        loss_train.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    train_losses = sum(loss_train) / len(loss_train)\n",
        "  \n",
        "    return train_losses\n",
        "\n",
        "def evaluate_fn(model, device, val_loader, max_len=MAX_LEN_TRGT):\n",
        "    loss_val, all_acc, all_preds, all_trues = [], [], [], []\n",
        "    model.eval()\n",
        "    for source_token_ids, source_mask, target_token_ids in val_loader:\n",
        "        predicted_ids = model.generate(\n",
        "            source_token_ids.to(device), \n",
        "            source_mask.to(device),\n",
        "            max_len\n",
        "            )\n",
        "        \n",
        "        preds = [TOK.decode(t) for t in predicted_ids]\n",
        "        trues = [TOK.decode(t) for t in target_token_ids]\n",
        "        acc = acc_in_text(trues, preds)\n",
        "        all_acc.extend(acc)\n",
        "        all_trues.extend(trues)\n",
        "        all_preds.extend(preds)\n",
        "        \n",
        "        # val loss   \n",
        "        loss = model(\n",
        "        source_token_ids.to(device), \n",
        "        source_mask.to(device), \n",
        "        target_token_ids.to(device)\n",
        "        )\n",
        "        loss_val.append(loss.item())\n",
        "    \n",
        "    val_losses = sum(loss_val) / len(loss_val)\n",
        "    \n",
        "    return val_losses, np.array(all_acc).mean(), all_trues, all_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pirS1mecELqp",
        "colab_type": "text"
      },
      "source": [
        "# Overfit in one batch \n",
        "- dataloader debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2PxRYyfn_UO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "overfit = False\n",
        "\n",
        "if overfit:\n",
        "\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "    deterministic() \n",
        "\n",
        "    model = Net().to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "    \n",
        "    # -----------------------------------------------------------------------------\n",
        "    start.record()\n",
        "    for step in range(1, 1001):\n",
        "        samp = random.randint(0, BATCH_SZ-WINDOW) # to show random trues and preds\n",
        "        loss_t = train(model, device, dataloaders['debug'], optimizer)\n",
        "        acc, trues, preds = evaluate_fn(model, device, dataloaders['debug'])\n",
        "        if step == 1:\n",
        "            print(f'[Epoch: {step}/{1000}] |', end=' ')\n",
        "            print(f'Train Loss: {loss_t:.3f} -- Acc: {acc:.3f}')\n",
        "        if step % 100 == 0:\n",
        "            print(f'[Epoch: {step}/{1000}] |', end=' ')\n",
        "            print(f'Train Loss: {loss_t:.3f} -- Acc: {acc:.3f}')\n",
        "            print(f'  Trues: {trues[samp:samp+WINDOW]}\\n  Preds: {preds[samp:samp+WINDOW]}')\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()    \n",
        "    # -----------------------------------------------------------------------------\n",
        "\n",
        "    print(f'Training time: {start.elapsed_time(end)/1000/60 :.3f} min.')\n",
        "    del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQC8YJ8PT7-0",
        "colab_type": "text"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNtIb8b4Q4lC",
        "colab_type": "code",
        "outputId": "ff6586d0-a8f0-4d91-a4a4-f4208f06a20a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# del model\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "deterministic() \n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "start.record()\n",
        "for step in range(1, N_EPOCHS+1):\n",
        "    samp = random.randint(0, BATCH_SZ-WINDOW) # to show random trues and preds\n",
        "    loss_t = train(model, device, dataloaders['train'], optimizer)\n",
        "    loss_v, acc, trues, preds = evaluate_fn(model, device, dataloaders['valid'])\n",
        "    print(f'[Epoch: {step}/{N_EPOCHS}] |', end=' ')\n",
        "    print(f'Train Loss: {loss_t:.3f} -- Valid Loss: {loss_v:.3f} -- Acc: {acc:.3f}')\n",
        "    print(f'  Trues: {trues[samp:samp+WINDOW]}\\n  Preds: {preds[samp:samp+WINDOW]}')\n",
        "\n",
        "end.record()\n",
        "torch.cuda.synchronize()    \n",
        "# ---------------------------------------------------------------------------------\n",
        "\n",
        "print(f'Training time: {start.elapsed_time(end)/1000/60 :.3f} min.')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deterministic experiment, seed: 2357\n",
            "[Epoch: 1/50] | Train Loss: 3.472 -- Valid Loss: 0.913 -- Acc: 0.025\n",
            "  Trues: ['07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049', '07/2051']\n",
            "  Preds: ['', '', '', '', '', '', '']\n",
            "[Epoch: 2/50] | Train Loss: 1.051 -- Valid Loss: 0.522 -- Acc: 0.149\n",
            "  Trues: ['29/01', '06/1951', '04/1970', '10/2049', '07/2051', '10/2029', '24/04']\n",
            "  Preds: ['29/09', '01/1951', '04/1999', '', '07/2051', '2029', '24/24']\n",
            "[Epoch: 3/50] | Train Loss: 0.622 -- Valid Loss: 0.413 -- Acc: 0.236\n",
            "  Trues: ['09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049']\n",
            "  Preds: ['09/1999', '07/2007', '10/1969', '29/02', '07/1951', '04/1999', '02/1994']\n",
            "[Epoch: 4/50] | Train Loss: 0.498 -- Valid Loss: 0.372 -- Acc: 0.290\n",
            "  Trues: ['08/2064', '09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970']\n",
            "  Preds: ['02/2064', '09/1999', '07/2007', '10/1969', '29/02', '07/1951', '04/1999']\n",
            "[Epoch: 5/50] | Train Loss: 0.438 -- Valid Loss: 0.340 -- Acc: 0.307\n",
            "  Trues: ['02/2046', '11/1991', '09/2005', '08/2064', '09/09', '07/2007', '10/1969']\n",
            "  Preds: ['02/1946', '02/1991', '03/2005', '02/2064', '09/1999', '07/2007', '10/1969']\n",
            "[Epoch: 6/50] | Train Loss: 0.405 -- Valid Loss: 0.314 -- Acc: 0.332\n",
            "  Trues: ['11/1991', '09/2005', '08/2064', '09/09', '07/2007', '10/1969', '29/01']\n",
            "  Preds: ['09/1991', '03/2005', '02/2064', '09/1999', '07/2007', '10/1969', '29/02']\n",
            "[Epoch: 7/50] | Train Loss: 0.371 -- Valid Loss: 0.294 -- Acc: 0.376\n",
            "  Trues: ['29/01', '06/1951', '04/1970', '10/2049', '07/2051', '10/2029', '24/04']\n",
            "  Preds: ['29/02', '07/1951', '04/1999', '11/2059', '07/2051', '10/2029', '24/00']\n",
            "[Epoch: 8/50] | Train Loss: 0.349 -- Valid Loss: 0.273 -- Acc: 0.425\n",
            "  Trues: ['10/1969', '29/01', '06/1951', '04/1970', '10/2049', '07/2051', '10/2029']\n",
            "  Preds: ['10/1969', '29/01', '07/1951', '04/1999', '11/2059', '07/2051', '10/2029']\n",
            "[Epoch: 9/50] | Train Loss: 0.329 -- Valid Loss: 0.255 -- Acc: 0.450\n",
            "  Trues: ['29/01', '06/1951', '04/1970', '10/2049', '07/2051', '10/2029', '24/04']\n",
            "  Preds: ['29/01', '07/1951', '04/1999', '10/2059', '07/2051', '10/2029', '24/08']\n",
            "[Epoch: 10/50] | Train Loss: 0.307 -- Valid Loss: 0.238 -- Acc: 0.472\n",
            "  Trues: ['07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049', '07/2051']\n",
            "  Preds: ['07/2007', '10/1969', '29/01', '07/1951', '04/1937', '10/2059', '07/2051']\n",
            "[Epoch: 11/50] | Train Loss: 0.291 -- Valid Loss: 0.221 -- Acc: 0.528\n",
            "  Trues: ['10/1969', '29/01', '06/1951', '04/1970', '10/2049', '07/2051', '10/2029']\n",
            "  Preds: ['10/1969', '29/01', '06/1951', '04/1937', '10/2041', '07/2051', '10/2029']\n",
            "[Epoch: 12/50] | Train Loss: 0.270 -- Valid Loss: 0.206 -- Acc: 0.554\n",
            "  Trues: ['09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049']\n",
            "  Preds: ['05/1999', '07/2007', '10/1969', '29/01', '06/1951', '04/1937', '10/2041']\n",
            "[Epoch: 13/50] | Train Loss: 0.257 -- Valid Loss: 0.195 -- Acc: 0.559\n",
            "  Trues: ['04/1970', '10/2049', '07/2051', '10/2029', '24/04', '06/2096', '13/11']\n",
            "  Preds: ['04/1987', '10/2041', '07/2051', '10/2029', '24/08', '06/2046', '11/11']\n",
            "[Epoch: 14/50] | Train Loss: 0.238 -- Valid Loss: 0.184 -- Acc: 0.572\n",
            "  Trues: ['02/2046', '11/1991', '09/2005', '08/2064', '09/09', '07/2007', '10/1969']\n",
            "  Preds: ['02/2046', '11/1991', '09/2005', '08/2064', '05/1999', '07/2007', '10/1969']\n",
            "[Epoch: 15/50] | Train Loss: 0.227 -- Valid Loss: 0.175 -- Acc: 0.583\n",
            "  Trues: ['11/1991', '09/2005', '08/2064', '09/09', '07/2007', '10/1969', '29/01']\n",
            "  Preds: ['11/1991', '09/2005', '08/2064', '05/1999', '07/2007', '10/1969', '29/01']\n",
            "[Epoch: 16/50] | Train Loss: 0.213 -- Valid Loss: 0.166 -- Acc: 0.586\n",
            "  Trues: ['29/01', '06/1951', '04/1970', '10/2049', '07/2051', '10/2029', '24/04']\n",
            "  Preds: ['29/01', '06/1951', '04/1987', '10/2041', '07/2051', '10/2029', '24/08']\n",
            "[Epoch: 17/50] | Train Loss: 0.198 -- Valid Loss: 0.160 -- Acc: 0.603\n",
            "  Trues: ['09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049']\n",
            "  Preds: ['05/1994', '07/2007', '10/1969', '29/01', '06/1951', '04/1987', '10/2041']\n",
            "[Epoch: 18/50] | Train Loss: 0.192 -- Valid Loss: 0.154 -- Acc: 0.623\n",
            "  Trues: ['09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049']\n",
            "  Preds: ['05/1999', '07/2007', '10/1969', '29/01', '06/1951', '04/1987', '10/2041']\n",
            "[Epoch: 19/50] | Train Loss: 0.183 -- Valid Loss: 0.149 -- Acc: 0.637\n",
            "  Trues: ['11/1991', '09/2005', '08/2064', '09/09', '07/2007', '10/1969', '29/01']\n",
            "  Preds: ['11/1991', '09/2005', '08/2064', '05/1994', '07/2007', '10/1969', '29/01']\n",
            "[Epoch: 20/50] | Train Loss: 0.174 -- Valid Loss: 0.143 -- Acc: 0.653\n",
            "  Trues: ['09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049']\n",
            "  Preds: ['05/1999', '07/2007', '10/1969', '29/01', '06/1951', '04/1987', '10/2041']\n",
            "[Epoch: 21/50] | Train Loss: 0.164 -- Valid Loss: 0.137 -- Acc: 0.666\n",
            "  Trues: ['04/1970', '10/2049', '07/2051', '10/2029', '24/04', '06/2096', '13/11']\n",
            "  Preds: ['04/1987', '10/2041', '07/2051', '10/2029', '24/08', '06/2096', '03/11']\n",
            "[Epoch: 22/50] | Train Loss: 0.160 -- Valid Loss: 0.131 -- Acc: 0.682\n",
            "  Trues: ['08/2064', '09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970']\n",
            "  Preds: ['08/2064', '05/1999', '07/2007', '10/1969', '29/01', '06/1951', '04/1987']\n",
            "[Epoch: 23/50] | Train Loss: 0.151 -- Valid Loss: 0.127 -- Acc: 0.684\n",
            "  Trues: ['11/1991', '09/2005', '08/2064', '09/09', '07/2007', '10/1969', '29/01']\n",
            "  Preds: ['11/1991', '09/2005', '08/2064', '05/1990', '07/2007', '10/1969', '29/01']\n",
            "[Epoch: 24/50] | Train Loss: 0.146 -- Valid Loss: 0.122 -- Acc: 0.702\n",
            "  Trues: ['29/01', '06/1951', '04/1970', '10/2049', '07/2051', '10/2029', '24/04']\n",
            "  Preds: ['29/01', '06/1951', '04/1987', '10/2049', '07/2051', '10/2029', '24/08']\n",
            "[Epoch: 25/50] | Train Loss: 0.138 -- Valid Loss: 0.119 -- Acc: 0.719\n",
            "  Trues: ['09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049']\n",
            "  Preds: ['05/1990', '07/2007', '10/1969', '29/01', '06/1951', '04/1987', '10/2049']\n",
            "[Epoch: 26/50] | Train Loss: 0.133 -- Valid Loss: 0.115 -- Acc: 0.721\n",
            "  Trues: ['08/2064', '09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970']\n",
            "  Preds: ['08/2064', '05/1990', '07/2007', '10/1969', '29/01', '06/1951', '04/1987']\n",
            "[Epoch: 27/50] | Train Loss: 0.127 -- Valid Loss: 0.113 -- Acc: 0.731\n",
            "  Trues: ['09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049']\n",
            "  Preds: ['05/1990', '07/2007', '10/1969', '29/01', '06/1951', '04/1987', '10/2049']\n",
            "[Epoch: 28/50] | Train Loss: 0.122 -- Valid Loss: 0.107 -- Acc: 0.751\n",
            "  Trues: ['08/2064', '09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970']\n",
            "  Preds: ['08/2064', '05/1990', '07/2007', '10/1969', '29/01', '06/1951', '04/1987']\n",
            "[Epoch: 29/50] | Train Loss: 0.117 -- Valid Loss: 0.109 -- Acc: 0.751\n",
            "  Trues: ['10/1969', '29/01', '06/1951', '04/1970', '10/2049', '07/2051', '10/2029']\n",
            "  Preds: ['10/1969', '29/01', '06/1951', '04/1987', '10/2049', '07/2051', '10/2029']\n",
            "[Epoch: 30/50] | Train Loss: 0.104 -- Valid Loss: 0.104 -- Acc: 0.771\n",
            "  Trues: ['09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049']\n",
            "  Preds: ['05/1990', '07/2007', '10/1969', '29/01', '06/1951', '04/1987', '10/2049']\n",
            "[Epoch: 31/50] | Train Loss: 0.110 -- Valid Loss: 0.099 -- Acc: 0.777\n",
            "  Trues: ['29/01', '06/1951', '04/1970', '10/2049', '07/2051', '10/2029', '24/04']\n",
            "  Preds: ['29/01', '06/1951', '04/1987', '10/2049', '07/2051', '10/2029', '24/08']\n",
            "[Epoch: 32/50] | Train Loss: 0.109 -- Valid Loss: 0.098 -- Acc: 0.771\n",
            "  Trues: ['09/2005', '08/2064', '09/09', '07/2007', '10/1969', '29/01', '06/1951']\n",
            "  Preds: ['09/2005', '08/2064', '05/1994', '07/2007', '10/1969', '29/01', '06/1951']\n",
            "[Epoch: 33/50] | Train Loss: 0.100 -- Valid Loss: 0.096 -- Acc: 0.770\n",
            "  Trues: ['09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049']\n",
            "  Preds: ['05/1990', '07/2007', '10/1969', '29/01', '06/1951', '04/1987', '10/2049']\n",
            "[Epoch: 34/50] | Train Loss: 0.096 -- Valid Loss: 0.095 -- Acc: 0.770\n",
            "  Trues: ['08/2064', '09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970']\n",
            "  Preds: ['08/2064', '05/1990', '07/2007', '10/1969', '29/01', '06/1951', '04/1977']\n",
            "[Epoch: 35/50] | Train Loss: 0.093 -- Valid Loss: 0.094 -- Acc: 0.779\n",
            "  Trues: ['07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049', '07/2051']\n",
            "  Preds: ['07/2007', '10/1969', '29/01', '06/1951', '04/1977', '10/2049', '07/2051']\n",
            "[Epoch: 36/50] | Train Loss: 0.090 -- Valid Loss: 0.092 -- Acc: 0.782\n",
            "  Trues: ['29/01', '06/1951', '04/1970', '10/2049', '07/2051', '10/2029', '24/04']\n",
            "  Preds: ['29/01', '06/1951', '04/1987', '10/2049', '07/2051', '10/2029', '24/08']\n",
            "[Epoch: 37/50] | Train Loss: 0.088 -- Valid Loss: 0.089 -- Acc: 0.788\n",
            "  Trues: ['09/2005', '08/2064', '09/09', '07/2007', '10/1969', '29/01', '06/1951']\n",
            "  Preds: ['09/2005', '08/2064', '05/1990', '07/2007', '10/1969', '29/01', '06/1951']\n",
            "[Epoch: 38/50] | Train Loss: 0.081 -- Valid Loss: 0.088 -- Acc: 0.788\n",
            "  Trues: ['09/2005', '08/2064', '09/09', '07/2007', '10/1969', '29/01', '06/1951']\n",
            "  Preds: ['09/2005', '08/2064', '05/1990', '07/2007', '10/1969', '29/01', '06/1951']\n",
            "[Epoch: 39/50] | Train Loss: 0.079 -- Valid Loss: 0.089 -- Acc: 0.795\n",
            "  Trues: ['11/1991', '09/2005', '08/2064', '09/09', '07/2007', '10/1969', '29/01']\n",
            "  Preds: ['11/1991', '09/2005', '08/2064', '05/1990', '07/2007', '10/1969', '29/01']\n",
            "[Epoch: 40/50] | Train Loss: 0.081 -- Valid Loss: 0.087 -- Acc: 0.799\n",
            "  Trues: ['07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049', '07/2051']\n",
            "  Preds: ['07/2007', '10/1969', '29/01', '06/1951', '04/1987', '10/2049', '07/2051']\n",
            "[Epoch: 41/50] | Train Loss: 0.074 -- Valid Loss: 0.085 -- Acc: 0.799\n",
            "  Trues: ['06/1951', '04/1970', '10/2049', '07/2051', '10/2029', '24/04', '06/2096']\n",
            "  Preds: ['06/1951', '04/1987', '10/2049', '07/2051', '10/2029', '24/08', '06/2096']\n",
            "[Epoch: 42/50] | Train Loss: 0.076 -- Valid Loss: 0.086 -- Acc: 0.799\n",
            "  Trues: ['29/01', '06/1951', '04/1970', '10/2049', '07/2051', '10/2029', '24/04']\n",
            "  Preds: ['29/01', '06/1951', '04/1977', '10/2049', '07/2051', '10/2029', '24/08']\n",
            "[Epoch: 43/50] | Train Loss: 0.073 -- Valid Loss: 0.084 -- Acc: 0.802\n",
            "  Trues: ['07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049', '07/2051']\n",
            "  Preds: ['07/2007', '10/1969', '29/01', '06/1951', '04/1977', '10/2049', '07/2051']\n",
            "[Epoch: 44/50] | Train Loss: 0.070 -- Valid Loss: 0.085 -- Acc: 0.804\n",
            "  Trues: ['09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049']\n",
            "  Preds: ['05/1990', '07/2007', '10/1969', '29/01', '06/1951', '04/1977', '10/2049']\n",
            "[Epoch: 45/50] | Train Loss: 0.065 -- Valid Loss: 0.082 -- Acc: 0.806\n",
            "  Trues: ['09/09', '07/2007', '10/1969', '29/01', '06/1951', '04/1970', '10/2049']\n",
            "  Preds: ['03/1990', '07/2007', '10/1969', '29/01', '06/1951', '04/1977', '10/2049']\n",
            "[Epoch: 46/50] | Train Loss: 0.061 -- Valid Loss: 0.082 -- Acc: 0.799\n",
            "  Trues: ['29/01', '06/1951', '04/1970', '10/2049', '07/2051', '10/2029', '24/04']\n",
            "  Preds: ['29/01', '06/1951', '04/1977', '10/2049', '07/2051', '10/2029', '24/08']\n",
            "[Epoch: 47/50] | Train Loss: 0.063 -- Valid Loss: 0.081 -- Acc: 0.804\n",
            "  Trues: ['06/1951', '04/1970', '10/2049', '07/2051', '10/2029', '24/04', '06/2096']\n",
            "  Preds: ['06/1951', '04/1977', '10/2049', '07/2051', '10/2029', '24/08', '06/2096']\n",
            "[Epoch: 48/50] | Train Loss: 0.058 -- Valid Loss: 0.081 -- Acc: 0.808\n",
            "  Trues: ['04/1970', '10/2049', '07/2051', '10/2029', '24/04', '06/2096', '13/11']\n",
            "  Preds: ['04/1977', '10/2049', '07/2051', '10/2029', '24/08', '06/2096', '03/11']\n",
            "[Epoch: 49/50] | Train Loss: 0.057 -- Valid Loss: 0.081 -- Acc: 0.804\n",
            "  Trues: ['02/2046', '11/1991', '09/2005', '08/2064', '09/09', '07/2007', '10/1969']\n",
            "  Preds: ['02/2046', '11/1991', '09/2005', '08/2064', '05/1994', '07/2007', '10/1969']\n",
            "[Epoch: 50/50] | Train Loss: 0.056 -- Valid Loss: 0.080 -- Acc: 0.808\n",
            "  Trues: ['10/1969', '29/01', '06/1951', '04/1970', '10/2049', '07/2051', '10/2029']\n",
            "  Preds: ['10/1969', '29/01', '06/1951', '04/1977', '10/2049', '07/2051', '10/2029']\n",
            "Training time: 19.901 min.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWAhh3gOgg2c",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfRFVIBSgiau",
        "colab_type": "code",
        "outputId": "967a7ef6-3e16-49eb-f9f4-4bae745b9e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# ---------------------------------------------------------------------------------\n",
        "start.record()\n",
        "\n",
        "samp = random.randint(0, BATCH_SZ-WINDOW) # to show random trues and preds\n",
        "loss, acc, trues, preds = evaluate_fn(model, device, dataloaders['test'])\n",
        "print(f'Loss: {loss:.3f} -- Acc: {acc:.3f}')\n",
        "print(f' Trues: {trues[samp:samp+WINDOW]}\\n  Preds: {preds[samp:samp+WINDOW]}')\n",
        "\n",
        "end.record()\n",
        "torch.cuda.synchronize()    \n",
        "# ---------------------------------------------------------------------------------\n",
        "\n",
        "print(f'Test time: {start.elapsed_time(end)/1000/60 :.3f} min.')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.127 -- Acc: 0.717\n",
            " Trues: ['03/1922', '09/1922', '01/1923', '04/1923', '02/1924', '11/1924', '11/1925']\n",
            "  Preds: ['03/1922', '09/1922', '01/1923', '04/1933', '02/1924', '11/1924', '06/1925']\n",
            "Test time: 0.092 min.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzVjYAkNGVxJ",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating types for a same date\n",
        "\n",
        "Given a sample date, this section evaluates wich is the accuracy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DixMx530hPg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_for_a_same_date(date,model=model,tokenizer=TOK,verbose=True):\n",
        "  '''\n",
        "    Given a specific date, returns the accuracy in all evalueated types.\n",
        "    Also prints results per sample.\n",
        "  '''\n",
        "\n",
        "  results = []\n",
        "  \n",
        "  examples = datas.generate_demo(date=date)\n",
        "\n",
        "  for x,target in zip(examples['Generated Text'],examples['Origin Sample']):\n",
        "\n",
        "    prediction = model.generate_example(x,TOK)[0]\n",
        "\n",
        "    results.append(prediction == target)\n",
        "\n",
        "    if verbose:\n",
        "      print(f'Entrada: {x} -- Target: {target} --- Previsto: {prediction} --- {prediction == target}')\n",
        "\n",
        "  if verbose:\n",
        "    print(f'Total accuracy: {np.mean(results)}')\n",
        "\n",
        "  return np.mean(results)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlmH30k9iBKC",
        "colab_type": "code",
        "outputId": "00e42fff-e1b3-4783-e2a8-30dc908f7a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "'''\n",
        "  A date in the century with more dates occuring\n",
        "'''\n",
        "evaluate_for_a_same_date('11/07/1988')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entrada: onze de julho de 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: onze de jul de mil, novecentos e oitenta e oito -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: onze de julho de mil, novecentos e oitenta e oito -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: décimo primeiro dia do mês sete de mil, novecentos e oitenta e oito -- Target: 11/07/1988 --- Previsto: 12/1988 --- False\n",
            "Entrada: 11 de Julho de 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 de julho de mil, novecentos e oitenta e oito -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11-07 de mil, novecentos e oitenta e oito -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: onze - 07 - 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: onze de julho - 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11º de julho de 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11º - 07 - 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11º / 07 / 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11º / Julho / 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 / julho / 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: onze julho mil, novecentos e oitenta e oito -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 julho mil, novecentos e oitenta e oito -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11/07 mil, novecentos e oitenta e oito -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11.07 mil, novecentos e oitenta e oito -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11-07 mil, novecentos e oitenta e oito -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: onze/julho/mil, novecentos e oitenta e oito -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 do mês sete de 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11-7-1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 - 7 - 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11-07-1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 - 07 - 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11-julho-1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 - julho - 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11-jul-1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 - jul - 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11.7.1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 . 7 . 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11.07.1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 . 07 . 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11.julho.1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 . julho . 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11.jul.1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 . jul . 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11/07/1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 / 07 / 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11/julho/1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 / julho / 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11/jul/1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 / jul / 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11/7/1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Entrada: 11 / 7 / 1988 -- Target: 11/07/1988 --- Previsto: 11/1988 --- False\n",
            "Total accuracy: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZr2RlmzcjLV",
        "colab_type": "code",
        "outputId": "b0393526-4827-4ef9-a26e-310c7824a199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "'''\n",
        "  A date in a century with less dates occurring, but that is inside the\n",
        "  generated dataset\n",
        "'''\n",
        "evaluate_for_a_same_date('20/12/2015')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entrada: vinte de dezembro de 2015 -- Target: 20/12/2015 --- Previsto: 21/2015 --- False\n",
            "Entrada: vinte de dez de dois mil e quinze -- Target: 20/12/2015 --- Previsto: 22/2015 --- False\n",
            "Entrada: vinte de dezembro de dois mil e quinze -- Target: 20/12/2015 --- Previsto: 21/2015 --- False\n",
            "Entrada: vigésimo dia do mês doze de dois mil e quinze -- Target: 20/12/2015 --- Previsto: 21/2015 --- False\n",
            "Entrada: 20 de Dezembro de 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20 de dezembro de dois mil e quinze -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20-12 de dois mil e quinze -- Target: 20/12/2015 --- Previsto: 20/12 --- False\n",
            "Entrada: vinte - 12 - 2015 -- Target: 20/12/2015 --- Previsto: 12/2015 --- False\n",
            "Entrada: vinte de dezembro - 2015 -- Target: 20/12/2015 --- Previsto: 21/2015 --- False\n",
            "Entrada: 20º de dezembro de 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20º - 12 - 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20º / 12 / 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20º / Dezembro / 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20 / dezembro / 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: vinte dezembro dois mil e quinze -- Target: 20/12/2015 --- Previsto: 21/2015 --- False\n",
            "Entrada: 20 dezembro dois mil e quinze -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20/12 dois mil e quinze -- Target: 20/12/2015 --- Previsto: 20/12 --- False\n",
            "Entrada: 20.12 dois mil e quinze -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20-12 dois mil e quinze -- Target: 20/12/2015 --- Previsto: 20/12 --- False\n",
            "Entrada: vinte/dezembro/dois mil e quinze -- Target: 20/12/2015 --- Previsto: 21/2015 --- False\n",
            "Entrada: 20 do mês doze de 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20-12-2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20 - 12 - 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20-12-2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20 - 12 - 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20-dezembro-2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20 - dezembro - 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20-dez-2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20 - dez - 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20.12.2015 -- Target: 20/12/2015 --- Previsto: 20/12 --- False\n",
            "Entrada: 20 . 12 . 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20.12.2015 -- Target: 20/12/2015 --- Previsto: 20/12 --- False\n",
            "Entrada: 20 . 12 . 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20.dezembro.2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20 . dezembro . 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20.dez.2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20 . dez . 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20/12/2015 -- Target: 20/12/2015 --- Previsto: 20/12 --- False\n",
            "Entrada: 20 / 12 / 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20/dezembro/2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20 / dezembro / 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20/dez/2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20 / dez / 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Entrada: 20/12/2015 -- Target: 20/12/2015 --- Previsto: 20/12 --- False\n",
            "Entrada: 20 / 12 / 2015 -- Target: 20/12/2015 --- Previsto: 20/2015 --- False\n",
            "Total accuracy: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqonQb-kcjUY",
        "colab_type": "code",
        "outputId": "1e9a7fdd-ac6f-4a5e-d209-a498e8d2d3f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "'''\n",
        "  Evaluating for a date in a century out of the training range gives the worst\n",
        "  acc possible. (0)\n",
        "'''\n",
        "evaluate_for_a_same_date('25/12/2141')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entrada: vinte e cinco de dezembro de 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: vinte e cinco de dez de dois mil, cento e quarenta e um -- Target: 25/12/2141 --- Previsto: 25/2114 --- False\n",
            "Entrada: vinte e cinco de dezembro de dois mil, cento e quarenta e um -- Target: 25/12/2141 --- Previsto: 21/2104 --- False\n",
            "Entrada: vigésimo quinto dia do mês doze de dois mil, cento e quarenta e um -- Target: 25/12/2141 --- Previsto: 21/2104 --- False\n",
            "Entrada: 25 de Dezembro de 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25 de dezembro de dois mil, cento e quarenta e um -- Target: 25/12/2141 --- Previsto: 25/2114 --- False\n",
            "Entrada: 25-12 de dois mil, cento e quarenta e um -- Target: 25/12/2141 --- Previsto: 25/2111 --- False\n",
            "Entrada: vinte e cinco - 12 - 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: vinte e cinco de dezembro - 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25º de dezembro de 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25º - 12 - 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25º / 12 / 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25º / Dezembro / 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25 / dezembro / 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: vinte e cinco dezembro dois mil, cento e quarenta e um -- Target: 25/12/2141 --- Previsto: 25/2114 --- False\n",
            "Entrada: 25 dezembro dois mil, cento e quarenta e um -- Target: 25/12/2141 --- Previsto: 25/2114 --- False\n",
            "Entrada: 25/12 dois mil, cento e quarenta e um -- Target: 25/12/2141 --- Previsto: 25/2111 --- False\n",
            "Entrada: 25.12 dois mil, cento e quarenta e um -- Target: 25/12/2141 --- Previsto: 25/2114 --- False\n",
            "Entrada: 25-12 dois mil, cento e quarenta e um -- Target: 25/12/2141 --- Previsto: 25/2111 --- False\n",
            "Entrada: vinte e cinco/dezembro/dois mil, cento e quarenta e um -- Target: 25/12/2141 --- Previsto: 25/2114 --- False\n",
            "Entrada: 25 do mês doze de 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25-12-2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25 - 12 - 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25-12-2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25 - 12 - 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25-dezembro-2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25 - dezembro - 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25-dez-2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25 - dez - 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25.12.2141 -- Target: 25/12/2141 --- Previsto: 25/12 --- False\n",
            "Entrada: 25 . 12 . 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25.12.2141 -- Target: 25/12/2141 --- Previsto: 25/12 --- False\n",
            "Entrada: 25 . 12 . 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25.dezembro.2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25 . dezembro . 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25.dez.2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25 . dez . 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25/12/2141 -- Target: 25/12/2141 --- Previsto: 25/12/2141 --- True\n",
            "Entrada: 25 / 12 / 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25/dezembro/2141 -- Target: 25/12/2141 --- Previsto: 25/2141 --- False\n",
            "Entrada: 25 / dezembro / 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25/dez/2141 -- Target: 25/12/2141 --- Previsto: 25/2141 --- False\n",
            "Entrada: 25 / dez / 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Entrada: 25/12/2141 -- Target: 25/12/2141 --- Previsto: 25/12/2141 --- True\n",
            "Entrada: 25 / 12 / 2141 -- Target: 25/12/2141 --- Previsto: 25/241 --- False\n",
            "Total accuracy: 0.044444444444444446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.044444444444444446"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMnT5Sm-IPMt",
        "colab_type": "code",
        "outputId": "6ac72e31-e806-4090-f37d-b9c65288a5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "'''\n",
        "  An earlier date than the beggining of the generated dataset\n",
        "'''\n",
        "evaluate_for_a_same_date('27/05/1920')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entrada: vinte e sete de maio de 1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: vinte e sete de mai de mil, novecentos e vinte -- Target: 27/05/1920 --- Previsto: 26/1927 --- False\n",
            "Entrada: vinte e sete de maio de mil, novecentos e vinte -- Target: 27/05/1920 --- Previsto: 26/1927 --- False\n",
            "Entrada: vigésimo sétimo dia do mês cinco de mil, novecentos e vinte -- Target: 27/05/1920 --- Previsto: 25/1925 --- False\n",
            "Entrada: 27 de Maio de 1920 -- Target: 27/05/1920 --- Previsto: 27/2020 --- False\n",
            "Entrada: 27 de maio de mil, novecentos e vinte -- Target: 27/05/1920 --- Previsto: 27/1927 --- False\n",
            "Entrada: 27-05 de mil, novecentos e vinte -- Target: 27/05/1920 --- Previsto: 27/1927 --- False\n",
            "Entrada: vinte e sete - 05 - 1920 -- Target: 27/05/1920 --- Previsto: 25/1920 --- False\n",
            "Entrada: vinte e sete de maio - 1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27º de maio de 1920 -- Target: 27/05/1920 --- Previsto: 27/2020 --- False\n",
            "Entrada: 27º - 05 - 1920 -- Target: 27/05/1920 --- Previsto: 27/2020 --- False\n",
            "Entrada: 27º / 05 / 1920 -- Target: 27/05/1920 --- Previsto: 27/2020 --- False\n",
            "Entrada: 27º / Maio / 1920 -- Target: 27/05/1920 --- Previsto: 27/2020 --- False\n",
            "Entrada: 27 / maio / 1920 -- Target: 27/05/1920 --- Previsto: 27/2020 --- False\n",
            "Entrada: vinte e sete maio mil, novecentos e vinte -- Target: 27/05/1920 --- Previsto: 25/1927 --- False\n",
            "Entrada: 27 maio mil, novecentos e vinte -- Target: 27/05/1920 --- Previsto: 27/1927 --- False\n",
            "Entrada: 27/05 mil, novecentos e vinte -- Target: 27/05/1920 --- Previsto: 27/1927 --- False\n",
            "Entrada: 27.05 mil, novecentos e vinte -- Target: 27/05/1920 --- Previsto: 27/1927 --- False\n",
            "Entrada: 27-05 mil, novecentos e vinte -- Target: 27/05/1920 --- Previsto: 27/1927 --- False\n",
            "Entrada: vinte e sete/maio/mil, novecentos e vinte -- Target: 27/05/1920 --- Previsto: 26/1927 --- False\n",
            "Entrada: 27 do mês cinco de 1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27-5-1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27 - 5 - 1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27-05-1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27 - 05 - 1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27-maio-1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27 - maio - 1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27-mai-1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27 - mai - 1920 -- Target: 27/05/1920 --- Previsto: 27/05 --- False\n",
            "Entrada: 27.5.1920 -- Target: 27/05/1920 --- Previsto: 27/052 --- False\n",
            "Entrada: 27 . 5 . 1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27.05.1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27 . 05 . 1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27.maio.1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27 . maio . 1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27.mai.1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27 . mai . 1920 -- Target: 27/05/1920 --- Previsto: 27/05 --- False\n",
            "Entrada: 27/05/1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27 / 05 / 1920 -- Target: 27/05/1920 --- Previsto: 27/2020 --- False\n",
            "Entrada: 27/maio/1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27 / maio / 1920 -- Target: 27/05/1920 --- Previsto: 27/2020 --- False\n",
            "Entrada: 27/mai/1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27 / mai / 1920 -- Target: 27/05/1920 --- Previsto: 27/2020 --- False\n",
            "Entrada: 27/5/1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Entrada: 27 / 5 / 1920 -- Target: 27/05/1920 --- Previsto: 27/1920 --- False\n",
            "Total accuracy: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0jwndLKmxpX",
        "colab_type": "text"
      },
      "source": [
        "# Accuracy in dataset dates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpd5akZyAXyz",
        "colab_type": "text"
      },
      "source": [
        "## Inside dataset\n",
        "\n",
        "Dates into the interval that was used to built the synthetic dataset used for test and eval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfHmTxgDm19i",
        "colab_type": "code",
        "outputId": "f21d0465-3c66-45db-91a1-830a5e20bf99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "accs = []\n",
        "dates = []\n",
        "\n",
        "sampled_test = random.sample(list(df['Target'].values),50)\n",
        "\n",
        "print('acc test set: ',sampled_test)\n",
        "\n",
        "for date_sample in sampled_test:\n",
        "  accs.append(evaluate_for_a_same_date(date_sample,verbose=False))\n",
        "  dates.append(date_sample)\n",
        "  "
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc test set:  ['10/2081', '05/2003', '12/2107', '01/2031', '09/2077', '11/2096', '09/1965', '01/2091', '03/1955', '02/2009', '05/2085', '10/2024', '03/2051', '02/1933', '12/2087', '08/2067', '11/2074', '11/2076', '05/1931', '01/2102', '05/2110', '10/09', '06/2047', '09/1932', '06/1933', '17/02', '11/1936', '27/08', '08/2023', '07/2096', '01/1964', '01/2041', '01/2113', '04/2058', '02/2081', '06/2109', '01/1973', '01/2066', '05/1929', '08/2003', '07/1998', '02/1934', '02/2052', '08/2039', '10/1956', '01/1982', '02/2032', '09/1946', '06/1998', '04/1959']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-4276b868d3b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdate_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampled_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_for_a_same_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-95-f9167747fb30>\u001b[0m in \u001b[0;36mevaluate_for_a_same_date\u001b[0;34m(date, model, tokenizer, verbose)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Generated Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Origin Sample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/syntetic_data_Pt/date_text_generator.py\u001b[0m in \u001b[0;36mgenerate_demo\u001b[0;34m(self, date)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mgenerated_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmethod_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdate_text_gen_method\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_gen_methods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxzyKeRQoBTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(dates,accs)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.ylim([0.8, 1.01])\n",
        "plt.ylabel('Average accuracy on 45 formats')\n",
        "plt.xlabel('Canonical target')\n",
        "plt.title('Average accuracy on dates inside synthetic training dataset')\n",
        "print('Average of average accuracies: ',np.mean(accs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePEpzTU5A0Rx",
        "colab_type": "text"
      },
      "source": [
        "## Below dataset\n",
        "\n",
        "Dates lower than the synthetic dataset used for test and eval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8gnAWTcd5DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accs = []\n",
        "dates = []\n",
        "\n",
        "new_dataset = DateTextGenerator('01/01/1900','31/12/1920')\n",
        "\n",
        "new_df = new_dataset.generate_date_dataset()\n",
        "sampled_test = random.sample(list(new_df['Target'].values),20)\n",
        "\n",
        "print('acc test set: ',sampled_test)\n",
        "\n",
        "for date_sample in sampled_test:\n",
        "  accs.append(evaluate_for_a_same_date(date_sample,verbose=False))\n",
        "  dates.append(date_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4DFUtHoUA2c4",
        "colab": {}
      },
      "source": [
        "plt.plot(dates,accs)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.ylim([-0.01, 1.01])\n",
        "plt.ylabel('Average accuracy on 45 formats')\n",
        "plt.xlabel('Canonical target')\n",
        "plt.title('Average accuracy on dates below synthetic training dataset')\n",
        "print('Average of average accuracies: ',np.mean(accs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H0BR5SlBCCEr"
      },
      "source": [
        "## Above dataset\n",
        "\n",
        "Dates greater than the synthetic dataset used for test and eval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86KqAIP8ef_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accs = []\n",
        "dates = []\n",
        "\n",
        "new_dataset = DateTextGenerator('01/01/2121','31/12/2140')\n",
        "\n",
        "\n",
        "new_df = new_dataset.generate_date_dataset()\n",
        "sampled_test = random.sample(list(new_df['Target'].values),20)\n",
        "\n",
        "print('acc test set: ',sampled_test)\n",
        "\n",
        "for date_sample in sampled_test:\n",
        "  accs.append(evaluate_for_a_same_date(date_sample,verbose=False))\n",
        "  dates.append(date_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J2SP31YSCCFG",
        "colab": {}
      },
      "source": [
        "plt.plot(dates,accs)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.ylim([-0.01, 1.01])\n",
        "plt.ylabel('Average accuracy on 45 formats')\n",
        "plt.xlabel('Canonical target')\n",
        "plt.title('Average accuracy on dates above synthetic training dataset')\n",
        "print('Average of average accuracies: ',np.mean(accs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bvkIIgMNASY",
        "colab_type": "text"
      },
      "source": [
        "# The End"
      ]
    }
  ]
}