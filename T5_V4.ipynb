{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5-V4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15993ec9233a498a81ae605c8d74e0e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8d78ff1ce75346dcbf24ed44f227f287",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e24ead09cdf048369486df2f9c515871",
              "IPY_MODEL_781dacada1ce4e2da40b28ab2643418b"
            ]
          }
        },
        "8d78ff1ce75346dcbf24ed44f227f287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e24ead09cdf048369486df2f9c515871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8843d0ba8174f81a98fe8b0defa9d4e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2ada0f81aac45b5ba3f67616f3bd363"
          }
        },
        "781dacada1ce4e2da40b28ab2643418b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4c15ec57b9f946a59592c81533322d51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:13&lt;00:00, 56.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d4fb5861c8d4831a3837c13de666cb8"
          }
        },
        "a8843d0ba8174f81a98fe8b0defa9d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2ada0f81aac45b5ba3f67616f3bd363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c15ec57b9f946a59592c81533322d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d4fb5861c8d4831a3837c13de666cb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7209b981b8b476584d04a66cc25cc95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ba00c0967d104e9cb82bd8eec493e076",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f7fd4f6cab64adcab1cfc15f6ba5be9",
              "IPY_MODEL_1634999fcfa0434997b24337f9dd0db8"
            ]
          }
        },
        "ba00c0967d104e9cb82bd8eec493e076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f7fd4f6cab64adcab1cfc15f6ba5be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_29c9a560a5664c279c6753f1eb94f449",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1197,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1197,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78e0d3b9fce54e389c7592fbcfbfc149"
          }
        },
        "1634999fcfa0434997b24337f9dd0db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_333960d88deb486cb4d8830a96521467",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [50:44&lt;00:00, 2.54s/B]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_981ffdb66b654eb48623902188d2ffee"
          }
        },
        "29c9a560a5664c279c6753f1eb94f449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78e0d3b9fce54e389c7592fbcfbfc149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "333960d88deb486cb4d8830a96521467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "981ffdb66b654eb48623902188d2ffee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50732b399c7a430b8c0cb0e6fcb0a6f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b8b3aeeefa224551adb878800b7c50dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9fd8d100bfc8443fb339b0b2c6c1a6d1",
              "IPY_MODEL_5560f72a7cf4430b94ec2a398802f476"
            ]
          }
        },
        "b8b3aeeefa224551adb878800b7c50dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9fd8d100bfc8443fb339b0b2c6c1a6d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab922706ba4f42eba6c175b88b8138d1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 242136741,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 242136741,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a5604dbae15430a8c5b3b0c39eaedd2"
          }
        },
        "5560f72a7cf4430b94ec2a398802f476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc421789a29e41d8b30d048cd4725d33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 242M/242M [00:05&lt;00:00, 40.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_545fff5bd7a6482dbf7c78023e93b08d"
          }
        },
        "ab922706ba4f42eba6c175b88b8138d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a5604dbae15430a8c5b3b0c39eaedd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc421789a29e41d8b30d048cd4725d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "545fff5bd7a6482dbf7c78023e93b08d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/textnorms/date_text_norm/blob/master/T5_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcMfqlK-0HLY",
        "colab_type": "code",
        "outputId": "8d113c57-30a9-4111-9b56-73ef80890b58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May 26 13:28:29 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-1Lmkfv6g2j",
        "colab_type": "code",
        "outputId": "b4a88e62-e11d-4b9b-ba7b-0f67f4d2aaba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "! rm -rf date*\n",
        "! git clone https://github.com/textnorms/date_text_norm.git\n",
        "! cp -r date_text_norm/syntetic_data/ .\n",
        "\n",
        "!pip install -q num2words transformers\n",
        "! pip install -q transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'date_text_norm'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 84 (delta 45), reused 40 (delta 14), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (84/84), done.\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 4.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 665kB 12.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 17.8MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 42.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 38.4MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nok2mtt_1021",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Synthetic data generator\n",
        "from syntetic_data import DateTextGenerator\n",
        "\n",
        "# PyTorch\n",
        "import torch \n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhdTvVgiYBw0",
        "colab_type": "text"
      },
      "source": [
        "### Deterministic experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm7tAsiUYMOU",
        "colab_type": "code",
        "outputId": "a5bfec30-5df0-4391-b6d6-99cb4de02bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "manual_seed = 2357 # only primes, cuz I like\n",
        "def deterministic(rep=True):\n",
        "    if rep:\n",
        "        np.random.seed(manual_seed)\n",
        "        torch.manual_seed(manual_seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(manual_seed)\n",
        "            torch.cuda.manual_seed_all(manual_seed)\n",
        "        torch.backends.cudnn.enabled = False \n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        print(f'Deterministic experiment, seed: {manual_seed}')\n",
        "    else:\n",
        "        print('Random experiment')\n",
        "\n",
        "deterministic()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deterministic experiment, seed: 2357\n",
            "Using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFHYoyzwOHDO",
        "colab_type": "text"
      },
      "source": [
        "## Config constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r8O913HOK9F",
        "colab_type": "code",
        "outputId": "17be9de7-419f-4be6-fdd0-84fc4f29cb27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "15993ec9233a498a81ae605c8d74e0e3",
            "8d78ff1ce75346dcbf24ed44f227f287",
            "e24ead09cdf048369486df2f9c515871",
            "781dacada1ce4e2da40b28ab2643418b",
            "a8843d0ba8174f81a98fe8b0defa9d4e",
            "c2ada0f81aac45b5ba3f67616f3bd363",
            "4c15ec57b9f946a59592c81533322d51",
            "1d4fb5861c8d4831a3837c13de666cb8"
          ]
        }
      },
      "source": [
        "# Model params\n",
        "MODEL_SZ = 't5-small'\n",
        "TOK = T5Tokenizer.from_pretrained(MODEL_SZ)\n",
        "MAX_LEN_SRC  = 40\n",
        "MAX_LEN_TRGT = 12\n",
        "\n",
        "# Train params\n",
        "BATCH_SZ = 128\n",
        "N_EPOCHS = 4\n",
        "WINDOW   = 7"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15993ec9233a498a81ae605c8d74e0e3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yeoFiMYXe8Z",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ52EJP6Fy5v",
        "colab_type": "code",
        "outputId": "eaab01ac-2f61-49ee-e3a2-7f39a12f0403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "datas = DateTextGenerator(start_date='01/01/1900',\n",
        "                          end_date='31/12/2020',\n",
        "                          text_noise_rate=0.7)\n",
        "datas.generate_demo(date='27/11/1983') \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gerando demostraÃ§Ã£o dos formatos de datas geradas para a canÃ´nica: 27/11/1983\n",
            "MÃ©todo: 1 --- vinte e sete do onze de mil, novecentos e oitenta e trÃªs\n",
            "--------------------------------------------------\n",
            "MÃ©todo: 2 --- 27.11.1983\n",
            "--------------------------------------------------\n",
            "MÃ©todo: 3 --- vinte e sete de novembro de mil, novecentos e oitenta e trÃªs\n",
            "--------------------------------------------------\n",
            "MÃ©todo: 4 --- vinte e sete de nov de mil, novecentos e oitenta e trÃªs\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpMWc1TrNvKS",
        "colab_type": "code",
        "outputId": "bd6fc7ec-620b-43e6-c729-f29724b6652d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df = datas.generate_date_dataset(); df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tipo padrÃ£o</th>\n",
              "      <th>RuÃ­do</th>\n",
              "      <th>Entrada</th>\n",
              "      <th>CanÃ´nico</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>N/A</td>\n",
              "      <td>um do um de mil, novecentos</td>\n",
              "      <td>01/01/1900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>unexpected_space_noise</td>\n",
              "      <td>dois do u m de mil, nove centos</td>\n",
              "      <td>02/01/1900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>remove_char_noise</td>\n",
              "      <td>trÃª do um de ml, novecentos</td>\n",
              "      <td>03/01/1900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>N/A</td>\n",
              "      <td>quatro do um de mil, novecentos</td>\n",
              "      <td>04/01/1900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>remove_char_noise</td>\n",
              "      <td>cinco o um de mil, nvecentos</td>\n",
              "      <td>05/01/1900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176775</th>\n",
              "      <td>4</td>\n",
              "      <td>lookalike_replace_noise</td>\n",
              "      <td>vimte e sete de dez de dois mii e vinte</td>\n",
              "      <td>27/12/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176776</th>\n",
              "      <td>4</td>\n",
              "      <td>remove_char_noise</td>\n",
              "      <td>inte e oito de dez dedois mil e vinte</td>\n",
              "      <td>28/12/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176777</th>\n",
              "      <td>4</td>\n",
              "      <td>unexpected_space_noise</td>\n",
              "      <td>vint e e  nove de dez de dois mil e vinte</td>\n",
              "      <td>29/12/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176778</th>\n",
              "      <td>4</td>\n",
              "      <td>remove_char_noise</td>\n",
              "      <td>tria de dez de dois mil e vinte</td>\n",
              "      <td>30/12/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176779</th>\n",
              "      <td>4</td>\n",
              "      <td>lookalike_replace_noise</td>\n",
              "      <td>trinta e um de dez de dois nil e uinte</td>\n",
              "      <td>31/12/2020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>176780 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Tipo padrÃ£o  ...    CanÃ´nico\n",
              "0                1  ...  01/01/1900\n",
              "1                1  ...  02/01/1900\n",
              "2                1  ...  03/01/1900\n",
              "3                1  ...  04/01/1900\n",
              "4                1  ...  05/01/1900\n",
              "...            ...  ...         ...\n",
              "176775           4  ...  27/12/2020\n",
              "176776           4  ...  28/12/2020\n",
              "176777           4  ...  29/12/2020\n",
              "176778           4  ...  30/12/2020\n",
              "176779           4  ...  31/12/2020\n",
              "\n",
              "[176780 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjM4mpipxgaC",
        "colab_type": "code",
        "outputId": "1d535f5b-0376-4320-8974-e672fd1139ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Inpsecting noise rate per samples\n",
        "df['RuÃ­do'].value_counts()/len(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "N/A                        0.300272\n",
              "remove_char_noise          0.233799\n",
              "lookalike_replace_noise    0.232996\n",
              "unexpected_space_noise     0.232934\n",
              "Name: RuÃ­do, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uif9PsFKRrxI",
        "colab_type": "text"
      },
      "source": [
        "## Function to split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfBx9nMkQ7Q8",
        "colab_type": "code",
        "outputId": "4c6eb162-07d1-465d-cb4f-5232310190af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def split_data(data, labels, test_size=0.2):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        data,\n",
        "        labels,\n",
        "        shuffle=True, \n",
        "        test_size=test_size,\n",
        "        random_state=manual_seed\n",
        "        )\n",
        "    return x_train, x_test, y_train, y_test\n",
        "\n",
        "# creating test set\n",
        "x_train, x_test, y_train, y_test = split_data(df.Entrada.values, \n",
        "                                              df.CanÃ´nico.values, \n",
        "                                              test_size=0.2)\n",
        "\n",
        "# creating valid set\n",
        "x_train, x_val, y_train, y_val = split_data(x_train, \n",
        "                                            y_train, \n",
        "                                            test_size=0.2)\n",
        "\n",
        "# checking\n",
        "len(x_train), len(y_train), len(x_val), len(y_val), len(x_test), len(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(113139, 113139, 28285, 28285, 35356, 35356)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygsMXnkCyrVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DateDataset(Dataset):\n",
        "    def __init__(self, data, label, tokenizer, source_max_length, target_max_length):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "        self.source_max_length = source_max_length\n",
        "        self.target_max_length = target_max_length\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        source = self.data[idx]\n",
        "        target = self.label[idx]\n",
        "\n",
        "        source_tokenized = self.tokenizer.encode_plus(\n",
        "            f'{source} {self.tokenizer.eos_token}',\n",
        "            max_length=self.source_max_length,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors='pt')\n",
        "\n",
        "        target_tokenized = self.tokenizer.encode_plus(\n",
        "            f'{target} {self.tokenizer.eos_token}',\n",
        "            max_length=self.target_max_length,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors='pt')\n",
        "\n",
        "        source_token_ids = source_tokenized['input_ids'].squeeze()\n",
        "        source_mask = source_tokenized['attention_mask'].squeeze()\n",
        "        target_token_ids = target_tokenized['input_ids'].squeeze()\n",
        "        \n",
        "        return source_token_ids, source_mask, target_token_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cloyt0tIwIiD",
        "colab_type": "text"
      },
      "source": [
        "## Checking the DateDataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoKiQXCvwGrP",
        "colab_type": "code",
        "outputId": "beb9dabe-cf14-4ffd-b6ea-5a4f11893522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataset_debug = DateDataset(\n",
        "    x_train, \n",
        "    y_train,\n",
        "    TOK,\n",
        "    MAX_LEN_SRC,\n",
        "    MAX_LEN_TRGT,\n",
        "    )\n",
        "\n",
        "dataloader_checking = DataLoader(\n",
        "    dataset_debug, \n",
        "    batch_size=1, \n",
        "    shuffle=True, \n",
        "    num_workers=0\n",
        "    )\n",
        "\n",
        "source_token_ids, source_mask, target_token_ids = next(iter(dataloader_checking))\n",
        "print(f'source_token_ids:\\n {source_token_ids} --- shape:{source_token_ids.shape}')\n",
        "print(f'source_mask:\\n {source_mask} --- shape:{source_mask.shape}')\n",
        "print(f'target_token_ids:\\n {target_token_ids} --- shape:{target_token_ids.shape}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source_token_ids:\n",
            " tensor([[  103,   159,    20,   703,    52,     3,   173,    20, 15533,     6,\n",
            "             3,  5326,     3,    15,  3728,    32,     7,     3,    15,   150,\n",
            "          2169,     9,     3,    15,   561,     1,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]) --- shape:torch.Size([1, 40])\n",
            "source_mask:\n",
            " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]) --- shape:torch.Size([1, 40])\n",
            "target_token_ids:\n",
            " tensor([[11270, 24288, 13523,  4729,     1,     0,     0,     0,     0,     0,\n",
            "             0,     0]]) --- shape:torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG1O12UoWYaM",
        "colab_type": "text"
      },
      "source": [
        "## Datasets e Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7AlRyeOW8GN",
        "colab_type": "code",
        "outputId": "9290ddfa-d245-4b34-d131-97f8713899e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# datasets\n",
        "ds_debug = DateDataset(x_train[:BATCH_SZ], y_train[:BATCH_SZ], TOK, MAX_LEN_SRC, MAX_LEN_TRGT)\n",
        "ds_train = DateDataset(x_train, y_train, TOK, MAX_LEN_SRC, MAX_LEN_TRGT)\n",
        "ds_valid = DateDataset(x_val, y_val, TOK, MAX_LEN_SRC, MAX_LEN_TRGT)\n",
        "ds_test  = DateDataset(x_test, y_test, TOK, MAX_LEN_SRC, MAX_LEN_TRGT)\n",
        "\n",
        "print('Datasets len:')\n",
        "print(f'len ds_debug: {len(ds_debug)}')\n",
        "print(f'len ds_train: {len(ds_train)}')\n",
        "print(f'len ds_valid: {len(ds_valid)}')\n",
        "print(f'len ds_test:  {len(ds_test)}')\n",
        "\n",
        "# dataloaders\n",
        "dataloaders = {\n",
        "    'debug': DataLoader(\n",
        "         ds_debug,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=True,\n",
        "         num_workers=2,\n",
        "         pin_memory=True),\n",
        "    'train': DataLoader(\n",
        "         ds_train,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=True,\n",
        "         num_workers=2,\n",
        "         pin_memory=True),\n",
        "    'valid': DataLoader(\n",
        "         ds_valid,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=False,\n",
        "         num_workers=2,\n",
        "         pin_memory=True),\n",
        "    'test': DataLoader(\n",
        "         ds_test,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=False,\n",
        "         num_workers=2,\n",
        "         pin_memory=True),\n",
        "               }\n",
        "# sanity check\n",
        "print('\\nDataloaders len (in batch):')\n",
        "dl_sizes = {x: len(dataloaders[x]) for x in dataloaders.keys()}; dl_sizes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datasets len:\n",
            "len ds_debug: 128\n",
            "len ds_train: 113139\n",
            "len ds_valid: 28285\n",
            "len ds_test:  35356\n",
            "\n",
            "Dataloaders len (in batch):\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'debug': 1, 'test': 277, 'train': 884, 'valid': 221}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3rqg6r7am-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testando o dataloader \n",
        "source_token_ids, source_mask, target_token_ids = next(iter(dataloaders['test']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb4AnOJzBXK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_SZ)\n",
        "    \n",
        "    def forward(self, token_ids, att_mask, labels):\n",
        "        outputs = self.model.forward(\n",
        "            input_ids=token_ids, \n",
        "            attention_mask=att_mask,\n",
        "            lm_labels=labels\n",
        "            )\n",
        "        return outputs[0] # loss\n",
        "    \n",
        "    @torch.no_grad()    \n",
        "    def generate(self, token_ids, att_mask, max_len_target):\n",
        "        predict = self.model.generate(\n",
        "            input_ids=token_ids, \n",
        "            attention_mask=att_mask,\n",
        "            max_length=max_len_target\n",
        "            )\n",
        "        return predict\n",
        "    \n",
        "    @torch.no_grad()  \n",
        "    def generate_example(self, text_input, tokenizer, max_len_source=MAX_LEN_SRC):\n",
        "\n",
        "        self.model.eval()\n",
        "        \n",
        "        example_tokenized = tokenizer.encode_plus(\n",
        "            f'{text_input} {tokenizer.eos_token}',\n",
        "            max_length=max_len_source,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors='pt')\n",
        "            \n",
        "        example_token_ids = example_tokenized['input_ids']\n",
        "        example_mask = example_tokenized['attention_mask']\n",
        "\n",
        "        predicted_example = self.model.generate(\n",
        "            input_ids=example_token_ids.to(device), \n",
        "            attention_mask=example_mask.to(device),\n",
        "            max_length=MAX_LEN_TRGT\n",
        "            )\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        out_text = [tokenizer.decode(text) for text in predicted_example]\n",
        "        \n",
        "        return out_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq9AMCaNuWMU",
        "colab_type": "text"
      },
      "source": [
        "## Train and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X6hklAUXxGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# acc metric for text inputs\n",
        "def acc_in_text(trues, preds): \n",
        "    acc = []\n",
        "    for d in zip(trues, preds):\n",
        "        if d[0] == d[1]:\n",
        "            acc.append(1)\n",
        "        else:\n",
        "            acc.append(0)\n",
        "    return acc # bool\n",
        "\n",
        "def train(model, device, train_loader, optimizer):\n",
        "    loss_train = []\n",
        "    model.train()\n",
        "    for source_token_ids, source_mask, target_token_ids in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(\n",
        "            source_token_ids.to(device), \n",
        "            source_mask.to(device), \n",
        "            target_token_ids.to(device)\n",
        "            )\n",
        "        \n",
        "        loss_train.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "  \n",
        "    return sum(loss_train) / len(loss_train)\n",
        "\n",
        "def evaluate_fn(model, device, val_loader, max_len=MAX_LEN_TRGT):\n",
        "    all_acc, all_preds, all_trues = [], [], []\n",
        "    model.eval()\n",
        "    for source_token_ids, source_mask, target_token_ids in val_loader:\n",
        "        predicted_ids = model.generate(\n",
        "            source_token_ids.to(device), \n",
        "            source_mask.to(device),\n",
        "            max_len\n",
        "            )\n",
        "        \n",
        "        preds = [TOK.decode(t) for t in predicted_ids]\n",
        "        trues = [TOK.decode(t) for t in target_token_ids]\n",
        "        acc = acc_in_text(trues, preds)\n",
        "        all_acc.extend(acc)\n",
        "        all_trues.extend(trues)\n",
        "        all_preds.extend(preds)\n",
        "        \n",
        "    return np.array(all_acc).mean(), all_trues, all_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pirS1mecELqp",
        "colab_type": "text"
      },
      "source": [
        "# Overfit in one batch \n",
        "- dataloader debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2PxRYyfn_UO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "overfit = False\n",
        "\n",
        "if overfit:\n",
        "\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "    deterministic() \n",
        "\n",
        "    model = Net().to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "    \n",
        "    # -----------------------------------------------------------------------------\n",
        "    start.record()\n",
        "    for step in range(1, 1001):\n",
        "        samp = random.randint(0, BATCH_SZ-WINDOW) # to show random trues and preds\n",
        "        loss_t = train(model, device, dataloaders['debug'], optimizer)\n",
        "        acc, trues, preds = evaluate_fn(model, device, dataloaders['debug'])\n",
        "        if step == 1:\n",
        "            print(f'[Epoch: {step}/{1000}] |', end=' ')\n",
        "            print(f'Train Loss: {loss_t:.3f} -- Acc: {acc:.3f}')\n",
        "        if step % 100 == 0:\n",
        "            print(f'[Epoch: {step}/{1000}] |', end=' ')\n",
        "            print(f'Train Loss: {loss_t:.3f} -- Acc: {acc:.3f}')\n",
        "            print(f'  Trues: {trues[samp:samp+WINDOW]}\\n  Preds: {preds[samp:samp+WINDOW]}')\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()    \n",
        "    # -----------------------------------------------------------------------------\n",
        "\n",
        "    print(f'Training time: {start.elapsed_time(end)/1000/60 :.3f} min.')\n",
        "    del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQC8YJ8PT7-0",
        "colab_type": "text"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNtIb8b4Q4lC",
        "colab_type": "code",
        "outputId": "89f34ac2-9780-47af-d932-66c261957c9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353,
          "referenced_widgets": [
            "b7209b981b8b476584d04a66cc25cc95",
            "ba00c0967d104e9cb82bd8eec493e076",
            "0f7fd4f6cab64adcab1cfc15f6ba5be9",
            "1634999fcfa0434997b24337f9dd0db8",
            "29c9a560a5664c279c6753f1eb94f449",
            "78e0d3b9fce54e389c7592fbcfbfc149",
            "333960d88deb486cb4d8830a96521467",
            "981ffdb66b654eb48623902188d2ffee",
            "50732b399c7a430b8c0cb0e6fcb0a6f3",
            "b8b3aeeefa224551adb878800b7c50dd",
            "9fd8d100bfc8443fb339b0b2c6c1a6d1",
            "5560f72a7cf4430b94ec2a398802f476",
            "ab922706ba4f42eba6c175b88b8138d1",
            "6a5604dbae15430a8c5b3b0c39eaedd2",
            "bc421789a29e41d8b30d048cd4725d33",
            "545fff5bd7a6482dbf7c78023e93b08d"
          ]
        }
      },
      "source": [
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "deterministic() \n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "start.record()\n",
        "\n",
        "for step in range(1, N_EPOCHS+1):\n",
        "    samp = random.randint(0, BATCH_SZ-WINDOW) # to show random trues and preds\n",
        "    loss_t = train(model, device, dataloaders['train'], optimizer)\n",
        "    acc, trues, preds = evaluate_fn(model, device, dataloaders['valid'])\n",
        "    print(f'[Epoch: {step}/{N_EPOCHS}] |', end=' ')\n",
        "    print(f'Train Loss: {loss_t:.3f} -- Acc: {acc:.3f}')\n",
        "    print(f'  Trues: {trues[samp:samp+WINDOW]}\\n  Preds: {preds[samp:samp+WINDOW]}')\n",
        "\n",
        "end.record()\n",
        "torch.cuda.synchronize()    \n",
        "# ---------------------------------------------------------------------------------\n",
        "\n",
        "print(f'Training time: {start.elapsed_time(end)/1000/60 :.3f} min.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deterministic experiment, seed: 2357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7209b981b8b476584d04a66cc25cc95",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1197.0, style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50732b399c7a430b8c0cb0e6fcb0a6f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=242136741.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch: 1/4] | Train Loss: 0.889 -- Acc: 0.685\n",
            "  Trues: ['23/07/2003', '04/02/1934', '09/08/1933', '02/06/1958', '18/06/2005', '20/09/1988', '01/09/1937']\n",
            "  Preds: ['23/07/2003', '04/02/1934', '09/08/1933', '02/06/1958', '1806/2005', '20/09/1908', '01/09/1937']\n",
            "[Epoch: 2/4] | Train Loss: 0.152 -- Acc: 0.871\n",
            "  Trues: ['26/06/1980', '07/11/1957', '06/09/1934', '16/02/1909', '23/02/1981', '11/11/1967', '24/12/1986']\n",
            "  Preds: ['26/06/1980', '07/11/1957', '06/09/1934', '16/02/1909', '23/02/1981', '11/11/1967', '24/12/1938']\n",
            "[Epoch: 3/4] | Train Loss: 0.079 -- Acc: 0.917\n",
            "  Trues: ['19/10/1919', '14/09/1928', '22/03/1961', '09/01/1984', '06/02/1984', '27/02/2003', '06/03/2020']\n",
            "  Preds: ['19/10/1919', '14/09/1928', '22/03/1961', '09/01/1984', '06/02/1984', '27/02/2003', '06/03/2020']\n",
            "[Epoch: 4/4] | Train Loss: 0.055 -- Acc: 0.934\n",
            "  Trues: ['31/03/1921', '08/10/1932', '06/03/1971', '28/01/2008', '01/03/1908', '06/09/1975', '20/04/2009']\n",
            "  Preds: ['31/03/1921', '08/10/1932', '06/03/1971', '28/01/2008', '01/03/1908', '06/09/1975', '20/04/2009']\n",
            "Training time: 49.039 min.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWAhh3gOgg2c",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfRFVIBSgiau",
        "colab_type": "code",
        "outputId": "7f0da2cb-6d21-422f-9ebb-2567b52cf82b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# ---------------------------------------------------------------------------------\n",
        "start.record()\n",
        "\n",
        "samp = random.randint(0, BATCH_SZ-WINDOW) # to show random trues and preds\n",
        "acc, trues, preds = evaluate_fn(model, device, dataloaders['test'])\n",
        "print(f'Acc: {acc:.3f}')\n",
        "print(f' Trues: {trues[samp:samp+WINDOW]}\\n  Preds: {preds[samp:samp+WINDOW]}')\n",
        "\n",
        "end.record()\n",
        "torch.cuda.synchronize()    \n",
        "# ---------------------------------------------------------------------------------\n",
        "\n",
        "print(f'Test time: {start.elapsed_time(end)/1000/60 :.3f} min.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.936\n",
            " Trues: ['02/05/1961', '22/03/2020', '26/11/1948', '07/07/1939', '05/11/1945', '12/05/1922', '01/02/1931']\n",
            "  Preds: ['02/05/1961', '22/03/2020', '26/11/1948', '07/07/1939', '05/11/1945', '12/05/1922', '01/02/1931']\n",
            "Test time: 1.559 min.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzVjYAkNGVxJ",
        "colab_type": "text"
      },
      "source": [
        "# Predict an example\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQPXEekhM4xS",
        "colab_type": "code",
        "outputId": "b63f575f-5148-4cfe-8c12-75a971998dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_0 = 'un do janro de mil novecentu e otenta y sete'\n",
        "model.generate_example(data_0,TOK)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['01/01/1987']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb2oUfVV0BIc",
        "colab_type": "code",
        "outputId": "d9e83f13-6879-4b64-ffce-74c1f4cc27bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_1 = 'tr3$ d$ fev$ir0 d3 doi m1ll e novi'\n",
        "model.generate_example(data_1,TOK)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['03/02/2011']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bvkIIgMNASY",
        "colab_type": "text"
      },
      "source": [
        "# The End"
      ]
    }
  ]
}